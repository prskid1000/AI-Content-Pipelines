Workflow runner started. Python executable: C:\Users\prith\.pyenv\pyenv-win\versions\3.12.10\python.exe
Working directory: D:\.comfyui\gen.audio
Starting LM Studio backend via lms CLI...
Command: lms server start
Success! Server is now running on port 1234
Waiting for LM Studio to become ready (polling every 15s)...
LM Studio is ready after 0.1s (attempt 1).

===== START D:\.comfyui\gen.audio\scripts\12.media.py @ 2025-09-18 09:54:58 =====
Saved YouTube description to: ../output/description.txt (took 46.45s)

===== END D:\.comfyui\gen.audio\scripts\12.media.py @ 2025-09-18 09:55:45 (exit=0, took=46.59s) =====
Stopping LM Studio backend via lms CLI...
Command: lms server stop
Unloading all models from LM Studio...
Command: lms unload --all
Unloading "qwen/qwen3-14b"...
Unloaded 1 model.
Stopped the server on port 1234.
LM Studio appears stopped (after 1 checks).

Log time stats: writes=0.000s, flushes=0.051s, total=0.051s (~0.11% of runtime)

All scripts completed successfully.
