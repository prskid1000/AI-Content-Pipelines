Workflow runner started. Python executable: D:\.comfyui\.venv\Scripts\python.exe
Working directory: D:\.comfyui\gen.av
Emptying ComfyUI input and output folders...
Removed directory: D:\.comfyui\ComfyUI\input\3d
Removed file: D:\.comfyui\ComfyUI\input\scene_1.1.png
Successfully emptied ComfyUI input and output folders.
Starting ComfyUI backend using Windows cmd style...
Waiting for ComfyUI to become ready (polling every 15s)...
ComfyUI not ready yet (attempt 1). Retrying in 15s...
[START] Security scan
[DONE] Security scan
## ComfyUI-Manager: installing dependencies done.
** ComfyUI startup time: 2026-01-18 20:41:42.552
** Platform: Windows
** Python version: 3.12.5 (tags/v3.12.5:ff3bc82, Aug  6 2024, 20:45:27) [MSC v.1940 64 bit (AMD64)]
** Python executable: D:\.comfyui\.venv\Scripts\python.exe
** ComfyUI Path: D:\.comfyui\ComfyUI
** ComfyUI Base Folder Path: D:\.comfyui\ComfyUI
** User directory: D:\.comfyui\ComfyUI\user
** ComfyUI-Manager config path: D:\.comfyui\ComfyUI\user\__manager\config.ini
** Log path: D:\.comfyui\ComfyUI\user\comfyui.log

Prestartup times for custom nodes:
   6.8 seconds: D:\.comfyui\ComfyUI\custom_nodes\comfyui-manager

Checkpoint files will always be loaded safely.
Total VRAM 12227 MB, total RAM 64957 MB
pytorch version: 2.9.1+cu130
Set vram state to: NORMAL_VRAM
Device: cuda:0 NVIDIA GeForce RTX 5070 Ti Laptop GPU : cudaMallocAsync
Using async weight offloading with 16 streams
working around nvidia conv3d memory bug.
Found comfy_kitchen backend cuda: {'available': True, 'disabled': False, 'unavailable_reason': None, 'capabilities': ['apply_rope', 'apply_rope1', 'dequantize_nvfp4', 'dequantize_per_tensor_fp8', 'quantize_nvfp4', 'quantize_per_tensor_fp8', 'scaled_mm_nvfp4']}
Found comfy_kitchen backend triton: {'available': True, 'disabled': True, 'unavailable_reason': None, 'capabilities': ['apply_rope', 'apply_rope1', 'dequantize_nvfp4', 'dequantize_per_tensor_fp8', 'quantize_nvfp4', 'quantize_per_tensor_fp8']}
Found comfy_kitchen backend eager: {'available': True, 'disabled': False, 'unavailable_reason': None, 'capabilities': ['apply_rope', 'apply_rope1', 'dequantize_nvfp4', 'dequantize_per_tensor_fp8', 'quantize_nvfp4', 'quantize_per_tensor_fp8', 'scaled_mm_nvfp4']}
Using pytorch attention
ComfyUI not ready yet (attempt 2). Retrying in 15s...
Python version: 3.12.5 (tags/v3.12.5:ff3bc82, Aug  6 2024, 20:45:27) [MSC v.1940 64 bit (AMD64)]
ComfyUI version: 0.8.2
ComfyUI frontend version: 1.36.13
[Prompt Server] web root: D:\.comfyui\.venv\Lib\site-packages\comfyui_frontend_package\static
Total VRAM 12227 MB, total RAM 64957 MB
pytorch version: 2.9.1+cu130
Set vram state to: NORMAL_VRAM
Device: cuda:0 NVIDIA GeForce RTX 5070 Ti Laptop GPU : cudaMallocAsync
Using async weight offloading with 16 streams
ComfyUI-GGUF: Allowing full torch compile
### Loading: ComfyUI-Manager (V3.39.2)
[ComfyUI-Manager] network_mode: public
[ComfyUI-Manager] ComfyUI per-queue preview override detected (PR #11261). Manager's preview method feature is disabled. Use ComfyUI's --preview-method CLI option or 'Settings > Execution > Live preview method'.
### ComfyUI Revision: 4498 [2e9d5168] *DETACHED | Released on '2026-01-07'
[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json
[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json
[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json
[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json
[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json

[32mInitializing ControlAltAI Nodes[0m
ComfyUI not ready yet (attempt 3). Retrying in 15s...
Received signal 2. Cleaning up services...
Stopping ComfyUI backend...
ComfyUI appears stopped (after 1 checks).
