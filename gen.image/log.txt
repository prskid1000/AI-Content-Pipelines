Workflow runner started. Python executable: C:\Users\prith\.pyenv\pyenv-win\versions\3.12.10\python.exe
Working directory: D:\.comfyui\gen.image
Emptying ComfyUI input and output folders...
Successfully emptied ComfyUI input and output folders.
Starting LM Studio backend via lms CLI...
Command: lms server start
Success! Server is now running on port 1234
Waiting for LM Studio to become ready (polling every 15s)...
LM Studio is ready after 0.1s (attempt 1).

===== START D:\.comfyui\gen.image\scripts\1.story.py @ 2025-10-04 11:44:28 =====
Resumable mode enabled - checkpoint directory: D:\.comfyui\gen.image\output\tracking
Found existing checkpoint: D:\.comfyui\gen.image\output\tracking\1.story.state.json
Progress: Story(✓) Locations(8/8) Characters(6/6) CharSummaries(6/6) LocSummaries(8/8)
Extracted 8 unique locations: ['loc_1', 'loc_2', 'loc_3', 'loc_4', 'loc_5', 'loc_6', 'loc_7', 'loc_8']
Detected order: [] first, then ()(())
Running pre-validation checks...
Characters match: 6 names ['female_landlady_hudson', 'male_detective_holmes', 'male_doctor_watson', 'male_naval_lieutenant_graves', 'male_naval_officer', 'male_ship_steward_finch']
Pre-validation passed. Proceeding with generation...
Using cached story description from checkpoint
Generating structured location descriptions: 8 total
(1/8) loc_1: using cached description from checkpoint
(2/8) loc_2: using cached description from checkpoint
(3/8) loc_3: using cached description from checkpoint
(4/8) loc_4: using cached description from checkpoint
(5/8) loc_5: using cached description from checkpoint
(6/8) loc_6: using cached description from checkpoint
(7/8) loc_7: using cached description from checkpoint
(8/8) loc_8: using cached description from checkpoint
Wrote 8 detailed location entries to: D:\.comfyui\gen.image\input\2.location.txt
Generating location summaries: 8 total
(1/8) loc_1: using cached summary from checkpoint
(2/8) loc_2: using cached summary from checkpoint
(3/8) loc_3: using cached summary from checkpoint
(4/8) loc_4: using cached summary from checkpoint
(5/8) loc_5: using cached summary from checkpoint
(6/8) loc_6: using cached summary from checkpoint
(7/8) loc_7: using cached summary from checkpoint
(8/8) loc_8: using cached summary from checkpoint
Wrote 8 location summary entries to: D:\.comfyui\gen.image\input\3.location.txt
Generating structured character descriptions: 6 total
(1/6) female_landlady_hudson: using cached description from checkpoint
(2/6) male_detective_holmes: using cached description from checkpoint
(3/6) male_doctor_watson: using cached description from checkpoint
(4/6) male_naval_lieutenant_graves: using cached description from checkpoint
(5/6) male_naval_officer: using cached description from checkpoint
(6/6) male_ship_steward_finch: using cached description from checkpoint
Wrote 6 character descriptions to: D:\.comfyui\gen.image\input\2.character.txt
Generating character summaries: 6 total
(1/6) female_landlady_hudson: using cached summary from checkpoint
(2/6) male_detective_holmes: using cached summary from checkpoint
(3/6) male_doctor_watson: using cached summary from checkpoint
(4/6) male_naval_lieutenant_graves: using cached summary from checkpoint
(5/6) male_naval_officer: using cached summary from checkpoint
(6/6) male_ship_steward_finch: using cached summary from checkpoint
Wrote 6 character summaries to: D:\.comfyui\gen.image\input\3.character.txt
Wrote 71 dialogue lines to: D:\.comfyui\gen.audio\input\1.story.txt
Wrote 71 scene entries to: D:\.comfyui\gen.image\input\3.scene.txt
All operations completed successfully
Final progress: Progress: Story(✓) Locations(8/8) Characters(6/6) CharSummaries(6/6) LocSummaries(8/8)
All operations completed successfully - tracking files preserved

===== END D:\.comfyui\gen.image\scripts\1.story.py @ 2025-10-04 11:44:28 (exit=0, took=0.15s) =====

===== START D:\.comfyui\gen.audio\scripts\1.character.py @ 2025-10-04 11:44:28 =====
Resumable mode enabled - checkpoint directory: D:\.comfyui\gen.audio\output\tracking
No existing checkpoint found - starting fresh
=== VOICE REGION AND LANGUAGE SELECTION ===
Available regions: in
Available languages: ba, en, hi
Current region: in, Current language: en
[AUTO] Using --change-settings='n'
=== STORY PREPROCESSING ===
Found 6 unique characters: male_detective_holmes, male_naval_officer, female_landlady_hudson, male_ship_steward_finch, male_doctor_watson, male_naval_lieutenant_graves

Available male voices: alok_en, bala_en, gaurav_en, himanshu_en, indrajeet_en, nikhil_en, ramesh_en, sarang_en, sid_en, yuvraj_en
Available female voices: aisha_en, ayesha_en, deshna_en, henna_en, koku_en, maya_en, mona_en, mridula_en, paavni_en, vidya_en

=== CHARACTER VOICE ASSIGNMENT ===
I found the following characters in your story:
- male_detective_holmes
- male_naval_officer
- female_landlady_hudson
- male_ship_steward_finch
- male_doctor_watson
- male_naval_lieutenant_graves

Currently assigned voices:
- male_doctor_watson: alok_en
- male_detective_holmes: ramesh_en

Need to assign voices for: male_naval_officer, female_landlady_hudson, male_ship_steward_finch, male_naval_lieutenant_graves
Auto-assigned male voice 'bala_en' to 'male_naval_officer' (male_ prefix detected)
Auto-assigned female voice 'aisha_en' to 'female_landlady_hudson' (female_ prefix detected)
Auto-assigned male voice 'gaurav_en' to 'male_ship_steward_finch' (male_ prefix detected)
Auto-assigned male voice 'himanshu_en' to 'male_naval_lieutenant_graves' (male_ prefix detected)

=== FINAL CHARACTER-VOICE MAPPING ===
- male_detective_holmes: ramesh_en
- male_naval_officer: bala_en
- female_landlady_hudson: aisha_en
- male_ship_steward_finch: gaurav_en
- male_doctor_watson: alok_en
- male_naval_lieutenant_graves: himanshu_en
[AUTO] Using --auto-confirm='y'
Voice assignment confirmed!
Created backup: ../../ComfyUI/custom_nodes/tts_audio_suite/voices_examples/#character_alias_map.txt.backup
Updated character alias map file: ../../ComfyUI/custom_nodes/tts_audio_suite/voices_examples/#character_alias_map.txt
Format: character=voice

=== CHAPTER ANALYSIS AND SUMMARIZATION ===
📊 Story Statistics:
   📏 Total characters (excluding [names]): 10,127
   📝 Total words: 1,745
   📄 Total lines: 141

Story split into 3 chapters of ~50 lines each

Processing Chapter 1/3 (38.7% of story)...
   Lines 1-50 (3,923 chars)
✅ Chapter 1 generated:
   📖 Title: The Vanishing Gem
   📝 Summary words: 277 (target: 500)
   📏 Summary characters: 1797
   🔸 Short summary words: 18 (target: 20)
   ⏱️  Generation time: 18.17s

Processing Chapter 2/3 (32.7% of story)...
   Lines 51-100 (3,313 chars)
✅ Chapter 2 generated:
   📖 Title: Clay and Denial
   📝 Summary words: 281 (target: 500)
   📏 Summary characters: 1824
   🔸 Short summary words: 19 (target: 20)
   ⏱️  Generation time: 13.42s

Processing Chapter 3/3 (28.5% of story)...
   Lines 101-141 (2,887 chars)
✅ Chapter 3 generated:
   📖 Title: The Sapphire's Revelation
   📝 Summary words: 335 (target: 500)
   📏 Summary characters: 2142
   🔸 Short summary words: 21 (target: 20)
   ⏱️  Generation time: 14.14s
📄 Chapters saved to: ../input\12.chapters.txt

📚 CHAPTER BREAKDOWN
==========================================================================================
%    Chapter Title                  Words    Short    Status  
------------------------------------------------------------------------------------------
 39% The Vanishing Gem              277      18       ✅ OK    
 33% Clay and Denial                281      19       ✅ OK    
 29% The Sapphire's Revelation      335      21       ✅ OK    
------------------------------------------------------------------------------------------
TOT  3/3 chapters generated         -        -        DONE    
==========================================================================================

=== GENERATING META-SUMMARY ===
🔄 Re-summarizing 3 part summaries into comprehensive overview...
📝 Meta-summary statistics:
   🎯 Words: 893 (target: 1000-1200)
   📏 Characters: 5765
   ⏱️  Generation time: 31.68s
⚠️  Meta-summary word count outside target range (1000-1200)
✅ Meta-summary generated successfully
📄 Final summary saved to: ../input\9.description.txt

📊 SUMMARY STATISTICS TABLE
==========================================================================================
Part Input Lines  Input Words  Input Chars  Output Words  Output Chars  Status  
------------------------------------------------------------------------------------------
1    50           0            0            277           1797          ✅ OK    
2    50           0            0            281           1824          ✅ OK    
3    41           0            0            335           2142          ✅ OK    
------------------------------------------------------------------------------------------
PARTS 141          0            0            1500          -             PARTS   
FINAL -            -            -            893           5765          META    
==========================================================================================
📑 Parts processed: 3
✅ Successful: 3
❌ Failed: 0

=== GENERATING STORY TITLE ===
✅ Story title generated:
   📖 Title: The Mystery of the Stolen Sapphire
   ⏱️  Generation time: 3.17s
📄 Story title saved to: ../input\10.title.txt

🎉 Chapter analysis completed!
📊 Successfully generated 3 chapters
❌ Failed: 0 chapters

📚 Generated 3 chapter summaries
All operations completed successfully
Final progress: Progress: Voices(✓) Chapters(3/3) Meta(✓) Title(✓)
All operations completed successfully - tracking files preserved

==================================================
⏱️  TIMING SUMMARY
==================================================
⚙️  Setup time: 0.000 seconds
📖 Story reading time: 0.011 seconds
👥 Character preprocessing time: 82.657 seconds
⏱️  Total execution time: 82.668 seconds (1.378 minutes)
==================================================

===== END D:\.comfyui\gen.audio\scripts\1.character.py @ 2025-10-04 11:45:51 (exit=0, took=82.82s) =====

===== START D:\.comfyui\gen.audio\scripts\9.description.py @ 2025-10-04 11:45:51 =====
Length: 3516
Tokens: 572
Saved thumbnail prompt to: ../input/10.thumbnail.txt (took 22.20s)

===== END D:\.comfyui\gen.audio\scripts\9.description.py @ 2025-10-04 11:46:13 (exit=0, took=22.33s) =====
Stopping LM Studio backend via lms CLI...
Command: lms server stop
Unloading all models from LM Studio...
Command: lms unload --all
Unloading "qwen/qwen3-14b"...
Unloaded 1 model.
Stopped the server on port 1234.
LM Studio appears stopped (after 1 checks).
Starting ComfyUI backend using Windows cmd style...
Waiting for ComfyUI to become ready (polling every 15s)...
[START] Security scan
[DONE] Security scan
## ComfyUI-Manager: installing dependencies done.
** ComfyUI startup time: 2025-10-04 11:46:15.671
** Platform: Windows
** Python version: 3.12.10 (tags/v3.12.10:0cc8128, Apr  8 2025, 12:21:36) [MSC v.1943 64 bit (AMD64)]
** Python executable: C:\Users\prith\.pyenv\pyenv-win\versions\3.12.10\python.exe
** ComfyUI Path: D:\.comfyui\ComfyUI
** ComfyUI Base Folder Path: D:\.comfyui\ComfyUI
** User directory: D:\.comfyui\ComfyUI\user
** ComfyUI-Manager config path: D:\.comfyui\ComfyUI\user\default\ComfyUI-Manager\config.ini
** Log path: D:\.comfyui\ComfyUI\user\comfyui.log

Prestartup times for custom nodes:
   0.0 seconds: D:\.comfyui\ComfyUI\custom_nodes\rgthree-comfy
   1.8 seconds: D:\.comfyui\ComfyUI\custom_nodes\comfyui-manager

ComfyUI not ready yet (attempt 1). Retrying in 15s...
Checkpoint files will always be loaded safely.
Total VRAM 12227 MB, total RAM 64957 MB
pytorch version: 2.9.0.dev20250905+cu129
Set vram state to: NORMAL_VRAM
Device: cuda:0 NVIDIA GeForce RTX 5070 Ti Laptop GPU : cudaMallocAsync
Using pytorch attention
Python version: 3.12.10 (tags/v3.12.10:0cc8128, Apr  8 2025, 12:21:36) [MSC v.1943 64 bit (AMD64)]
ComfyUI version: 0.3.60
ComfyUI frontend version: 1.26.13
[Prompt Server] web root: C:\Users\prith\.pyenv\pyenv-win\versions\3.12.10\Lib\site-packages\comfyui_frontend_package\static
ComfyUI-GGUF: Allowing full torch compile
### Loading: ComfyUI-Impact-Pack (V8.22.2)
[Impact Pack] Wildcards loading done.
### Loading: ComfyUI-Manager (V3.36)
[ComfyUI-Manager] network_mode: public
### ComfyUI Version: v0.3.60-34-g39fd106d | Released on '2025-09-28'

[32mInitializing ControlAltAI Nodes[0m

[92m[rgthree-comfy] Loaded 48 epic nodes. 🎉[0m

[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json
[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json
[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json
[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json
[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json
✅ ChatterboxTTS loaded from bundled package
✅ ChatterboxVC loaded from bundled package
JAX version 0.7.1 available.
✅ F5-TTS loaded from system package
🎭 Character voices: Found 61 characters, 6 aliases
✅ SRT modules loaded from system package
🔧 Registering TTS Audio Suite nodes...
======================================================================
🚀 TTS Audio Suite v4.2.1
Universal multi-engine TTS extension for ComfyUI
⚠️ No local ChatterBox models found - will download from Hugging Face
💡 Tip: First generation will download models (~1GB)
   Models will be saved locally for future use
✅ TTS Audio Suite v4.2.1 loaded with 16 nodes:
   • ⚙️ ChatterBox TTS Engine
   • ⚙️ F5 TTS Engine
   • ⚙️ RVC Engine
   • 🌊 Audio Wave Analyzer
   • 🎙️ Voice Capture
   • 🎤 TTS Text
   • 🎭 Character Voices
   • 🎭 Load RVC Character Model
   • 👄 F5-TTS Speech Editor
   • 📺 TTS SRT
   • 🔄 Voice Changer
   • 🔧 Audio Analyzer Options
   • 🔧 F5-TTS Edit Options
   • 🔧 RVC Pitch Extraction Options
   • 🤐 Noise or Vocal Removal
   • 🥪 Merge Audio
======================================================================

Import times for custom nodes:
   0.0 seconds: D:\.comfyui\ComfyUI\custom_nodes\websocket_image_save.py
   0.0 seconds: D:\.comfyui\ComfyUI\custom_nodes\controlaltai-nodes
   0.0 seconds: D:\.comfyui\ComfyUI\custom_nodes\comfyui-kjnodes
   0.0 seconds: D:\.comfyui\ComfyUI\custom_nodes\rgthree-comfy
   0.0 seconds: D:\.comfyui\ComfyUI\custom_nodes\ComfyUI-GGUF
   0.1 seconds: D:\.comfyui\ComfyUI\custom_nodes\comfyui-videohelpersuite
   0.1 seconds: D:\.comfyui\ComfyUI\custom_nodes\comfyui-impact-pack
   0.3 seconds: D:\.comfyui\ComfyUI\custom_nodes\comfyui-manager
   1.7 seconds: D:\.comfyui\ComfyUI\custom_nodes\ComfyUI-LTXVideo
   3.8 seconds: D:\.comfyui\ComfyUI\custom_nodes\tts_audio_suite

Context impl SQLiteImpl.
Will assume non-transactional DDL.
No target revision found.
Starting server

To see the GUI go to: http://127.0.0.1:8188
FETCH ComfyRegistry Data: 5/99
ComfyUI is ready after 17.1s (attempt 2).

===== START D:\.comfyui\gen.audio\scripts\10.thumbnail.py @ 2025-10-04 11:46:31 =====
Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)
handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>
Traceback (most recent call last):
  File "C:\Users\prith\.pyenv\pyenv-win\versions\3.12.10\Lib\asyncio\events.py", line 88, in _run
    self._context.run(self._callback, *self._args)
  File "C:\Users\prith\.pyenv\pyenv-win\versions\3.12.10\Lib\asyncio\proactor_events.py", line 165, in _call_connection_lost
    self._sock.shutdown(socket.SHUT_RDWR)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host
Generating thumbnail (Serial LoRA mode)

Processing LoRA 1/1: FLUX.1-Turbo-Alpha.safetensors
Serial LoRA mode: 1 LoRAs will run independently
Note: Serial mode requires separate workflow execution for each LoRA
LoRA enabled in thumbnail workflow
Sampling steps set to: 25
Negative prompt enabled: blur, distorted, text, watermark, extra limbs, bad anatomy, poorly drawn, asymmetrical, malformed, disfigured, ugly, bad proportions, plastic texture, artificial looking, cross-eyed, missing fingers, extra fingers, bad teeth, missing teeth, unrealistic
  Model strength: 3.6
  CLIP strength: 3.6
Using latent mode with dimensions: 1280x720
  Seed set to: 133466324
  Using latent mode with dimensions: 1280x720
  Using LoRA denoising_strength: 0.8
  Steps: 9, Denoising: 0.8
got prompt
  Waiting for LoRA 1 generation to complete...
Using pytorch attention in VAE
Using pytorch attention in VAE
VAE load device: cuda:0, offload device: cpu, dtype: torch.bfloat16
CLIP/text encoder model load device: cuda:0, offload device: cpu, current: cpu, dtype: torch.float16
FETCH ComfyRegistry Data: 10/99
clip missing: ['text_projection.weight']
gguf qtypes: F32 (466), Q8_0 (304), BF16 (10)
model weight dtype torch.bfloat16, manual cast: None
model_type FLUX
Token indices sequence length is longer than the specified maximum sequence length for this model (977 > 512). Running this sequence through the model will result in indexing errors
Requested to load FluxClipModel_
FETCH ComfyRegistry Data: 15/99
loaded completely 9518.8 9319.23095703125 True
Requested to load Flux
FETCH ComfyRegistry Data: 20/99
FETCH ComfyRegistry Data: 25/99
FETCH ComfyRegistry Data: 30/99
loaded partially 9390.074961853028 9389.463134765625 0
Attempting to release mmap (127)
  0%|          | 0/9 [00:00<?, ?it/s]FETCH ComfyRegistry Data: 35/99
 11%|█         | 1/9 [00:05<00:41,  5.18s/it]FETCH ComfyRegistry Data: 40/99
 22%|██▏       | 2/9 [00:08<00:28,  4.00s/it] 33%|███▎      | 3/9 [00:11<00:21,  3.63s/it]FETCH ComfyRegistry Data: 45/99
 44%|████▍     | 4/9 [00:14<00:17,  3.47s/it]FETCH ComfyRegistry Data: 50/99
 56%|█████▌    | 5/9 [00:17<00:13,  3.36s/it] 67%|██████▋   | 6/9 [00:21<00:09,  3.30s/it]FETCH ComfyRegistry Data: 55/99
 78%|███████▊  | 7/9 [00:24<00:06,  3.26s/it] 89%|████████▉ | 8/9 [00:27<00:03,  3.24s/it]FETCH ComfyRegistry Data: 60/99
100%|██████████| 9/9 [00:30<00:00,  3.24s/it]100%|██████████| 9/9 [00:30<00:00,  3.41s/it]
Requested to load AutoencodingEngine
loaded completely 192.3203125 159.87335777282715 True
Prompt executed in 60.29 seconds
FETCH ComfyRegistry Data: 65/99
  Saved LoRA result: ../output/lora\thumbnail.FLUX.1_Turbo_Alpha.safetensors.png
  LoRA 1 completed successfully
Generating YouTube Shorts version 1 using ComfyUI...
Serial LoRA mode: 1 LoRAs will run independently
Note: Serial mode requires separate workflow execution for each LoRA
LoRA enabled in thumbnail workflow
Sampling steps set to: 25
Negative prompt enabled: blur, distorted, text, watermark, extra limbs, bad anatomy, poorly drawn, asymmetrical, malformed, disfigured, ugly, bad proportions, plastic texture, artificial looking, cross-eyed, missing fingers, extra fingers, bad teeth, missing teeth, unrealistic
Using latent mode with dimensions: 1080x1920
  Seed set to: 2441374793
got prompt
Failed to validate prompt for output 21:
* CLIPTextEncode 35:
  - Exception when validating inner node: 'lora_1'
Output will be ignored
invalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}
ERROR: ComfyUI API error for Shorts version 1: 400 {"error": {"type": "prompt_outputs_failed_validation", "message": "Prompt outputs failed validation", "details": "", "extra_info": {}}, "node_errors": {"35": {"errors": [{"type": "exception_during_inner_validation", "message": "Exception when validating inner node", "details": "'lora_1'", "extra_info": {"input_name": "negative", "input_config": ["CONDITIONING", {"tooltip": "The conditioning describing the attributes you want to exclude from the image."}], "exception_message": "'lora_1'", "exception_type": "KeyError", "traceback": ["  File \"D:\\.comfyui\\ComfyUI\\execution.py\", line 808, in validate_inputs\n    r = await validate_inputs(prompt_id, prompt, o_id, validated)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n", "  File \"D:\\.comfyui\\ComfyUI\\execution.py\", line 788, in validate_inputs\n    o_class_type = prompt[o_id]['class_type']\n                   ~~~~~~^^^^^^\n"], "linked_node": ["35", 0]}}], "dependent_outputs": ["21"], "class_type": "CLIPTextEncode"}}}
Generating YouTube Shorts version 2 using ComfyUI...
Serial LoRA mode: 1 LoRAs will run independently
Note: Serial mode requires separate workflow execution for each LoRA
LoRA enabled in thumbnail workflow
Sampling steps set to: 25
Negative prompt enabled: blur, distorted, text, watermark, extra limbs, bad anatomy, poorly drawn, asymmetrical, malformed, disfigured, ugly, bad proportions, plastic texture, artificial looking, cross-eyed, missing fingers, extra fingers, bad teeth, missing teeth, unrealistic
Using latent mode with dimensions: 1080x1920
  Seed set to: 3111566996
got prompt
Failed to validate prompt for output 21:
* CLIPTextEncode 35:
  - Exception when validating inner node: 'lora_1'
Output will be ignored
invalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}
ERROR: ComfyUI API error for Shorts version 2: 400 {"error": {"type": "prompt_outputs_failed_validation", "message": "Prompt outputs failed validation", "details": "", "extra_info": {}}, "node_errors": {"35": {"errors": [{"type": "exception_during_inner_validation", "message": "Exception when validating inner node", "details": "'lora_1'", "extra_info": {"input_name": "negative", "input_config": ["CONDITIONING", {"tooltip": "The conditioning describing the attributes you want to exclude from the image."}], "exception_message": "'lora_1'", "exception_type": "KeyError", "traceback": ["  File \"D:\\.comfyui\\ComfyUI\\execution.py\", line 808, in validate_inputs\n    r = await validate_inputs(prompt_id, prompt, o_id, validated)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n", "  File \"D:\\.comfyui\\ComfyUI\\execution.py\", line 788, in validate_inputs\n    o_class_type = prompt[o_id]['class_type']\n                   ~~~~~~^^^^^^\n"], "linked_node": ["35", 0]}}], "dependent_outputs": ["21"], "class_type": "CLIPTextEncode"}}}
Generating YouTube Shorts version 3 using ComfyUI...
Serial LoRA mode: 1 LoRAs will run independently
Note: Serial mode requires separate workflow execution for each LoRA
LoRA enabled in thumbnail workflow
Sampling steps set to: 25
Negative prompt enabled: blur, distorted, text, watermark, extra limbs, bad anatomy, poorly drawn, asymmetrical, malformed, disfigured, ugly, bad proportions, plastic texture, artificial looking, cross-eyed, missing fingers, extra fingers, bad teeth, missing teeth, unrealistic
Using latent mode with dimensions: 1080x1920
  Seed set to: 3168267404
got prompt
Failed to validate prompt for output 21:
* CLIPTextEncode 35:
  - Exception when validating inner node: 'lora_1'
Output will be ignored
invalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}
ERROR: ComfyUI API error for Shorts version 3: 400 {"error": {"type": "prompt_outputs_failed_validation", "message": "Prompt outputs failed validation", "details": "", "extra_info": {}}, "node_errors": {"35": {"errors": [{"type": "exception_during_inner_validation", "message": "Exception when validating inner node", "details": "'lora_1'", "extra_info": {"input_name": "negative", "input_config": ["CONDITIONING", {"tooltip": "The conditioning describing the attributes you want to exclude from the image."}], "exception_message": "'lora_1'", "exception_type": "KeyError", "traceback": ["  File \"D:\\.comfyui\\ComfyUI\\execution.py\", line 808, in validate_inputs\n    r = await validate_inputs(prompt_id, prompt, o_id, validated)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n", "  File \"D:\\.comfyui\\ComfyUI\\execution.py\", line 788, in validate_inputs\n    o_class_type = prompt[o_id]['class_type']\n                   ~~~~~~^^^^^^\n"], "linked_node": ["35", 0]}}], "dependent_outputs": ["21"], "class_type": "CLIPTextEncode"}}}
Generating YouTube Shorts version 4 using ComfyUI...
Serial LoRA mode: 1 LoRAs will run independently
Note: Serial mode requires separate workflow execution for each LoRA
LoRA enabled in thumbnail workflow
Sampling steps set to: 25
Negative prompt enabled: blur, distorted, text, watermark, extra limbs, bad anatomy, poorly drawn, asymmetrical, malformed, disfigured, ugly, bad proportions, plastic texture, artificial looking, cross-eyed, missing fingers, extra fingers, bad teeth, missing teeth, unrealistic
Using latent mode with dimensions: 1080x1920
  Seed set to: 2390493696
got prompt
Failed to validate prompt for output 21:
* CLIPTextEncode 35:
  - Exception when validating inner node: 'lora_1'
Output will be ignored
invalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}
ERROR: ComfyUI API error for Shorts version 4: 400 {"error": {"type": "prompt_outputs_failed_validation", "message": "Prompt outputs failed validation", "details": "", "extra_info": {}}, "node_errors": {"35": {"errors": [{"type": "exception_during_inner_validation", "message": "Exception when validating inner node", "details": "'lora_1'", "extra_info": {"input_name": "negative", "input_config": ["CONDITIONING", {"tooltip": "The conditioning describing the attributes you want to exclude from the image."}], "exception_message": "'lora_1'", "exception_type": "KeyError", "traceback": ["  File \"D:\\.comfyui\\ComfyUI\\execution.py\", line 808, in validate_inputs\n    r = await validate_inputs(prompt_id, prompt, o_id, validated)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n", "  File \"D:\\.comfyui\\ComfyUI\\execution.py\", line 788, in validate_inputs\n    o_class_type = prompt[o_id]['class_type']\n                   ~~~~~~^^^^^^\n"], "linked_node": ["35", 0]}}], "dependent_outputs": ["21"], "class_type": "CLIPTextEncode"}}}
Generating YouTube Shorts version 5 using ComfyUI...
Serial LoRA mode: 1 LoRAs will run independently
Note: Serial mode requires separate workflow execution for each LoRA
LoRA enabled in thumbnail workflow
Sampling steps set to: 25
Negative prompt enabled: blur, distorted, text, watermark, extra limbs, bad anatomy, poorly drawn, asymmetrical, malformed, disfigured, ugly, bad proportions, plastic texture, artificial looking, cross-eyed, missing fingers, extra fingers, bad teeth, missing teeth, unrealistic
Using latent mode with dimensions: 1080x1920
  Seed set to: 1748876539
got prompt
Failed to validate prompt for output 21:
* CLIPTextEncode 35:
  - Exception when validating inner node: 'lora_1'
Output will be ignored
invalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}
ERROR: ComfyUI API error for Shorts version 5: 400 {"error": {"type": "prompt_outputs_failed_validation", "message": "Prompt outputs failed validation", "details": "", "extra_info": {}}, "node_errors": {"35": {"errors": [{"type": "exception_during_inner_validation", "message": "Exception when validating inner node", "details": "'lora_1'", "extra_info": {"input_name": "negative", "input_config": ["CONDITIONING", {"tooltip": "The conditioning describing the attributes you want to exclude from the image."}], "exception_message": "'lora_1'", "exception_type": "KeyError", "traceback": ["  File \"D:\\.comfyui\\ComfyUI\\execution.py\", line 808, in validate_inputs\n    r = await validate_inputs(prompt_id, prompt, o_id, validated)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n", "  File \"D:\\.comfyui\\ComfyUI\\execution.py\", line 788, in validate_inputs\n    o_class_type = prompt[o_id]['class_type']\n                   ~~~~~~^^^^^^\n"], "linked_node": ["35", 0]}}], "dependent_outputs": ["21"], "class_type": "CLIPTextEncode"}}}
Saved: ../output\thumbnail.png
../output\thumbnail.png

===== END D:\.comfyui\gen.audio\scripts\10.thumbnail.py @ 2025-10-04 11:47:36 (exit=0, took=64.49s) =====
Stopping ComfyUI backend...
ComfyUI appears stopped (after 1 checks).
Starting LM Studio backend via lms CLI...
Command: lms server start
Success! Server is now running on port 1234
Waiting for LM Studio to become ready (polling every 15s)...
LM Studio is ready after 0.0s (attempt 1).

===== START D:\.comfyui\gen.audio\scripts\12.media.py @ 2025-10-04 11:47:38 =====
🔍 Reading diffusion text...
✅ Read 5765 characters from diffusion file
📖 Reading title...
✅ Title: The Mystery of the Stolen Sapphire
⏱️ Calculating audio duration...
✅ Total duration: 11:16 (676.9s)
🎯 Generating title line...
✅ Title line: 💎 The Mystery of the Stolen Sapphire | Sherlock Holmes Audiobook | Mystery Audiobook
🪝 Generating hook...
✅ Hook: 🕵️‍♂️ A stolen sapphire, a naval officer’s despair, and a clue hidden in red clay—Holmes and Watson race against time to uncover the truth aboard the Dauntless.
📋 Generating bullet points...
✅ Generated 5 bullet points
📚 Generating chapters from file...
✅ Generated 3 chapters
   00:00 - The Vanishing Gem
   07:33 - Clay and Denial
   08:00 - The Sapphire's Revelation
📢 Generating CTAs...
✅ Generated 3 CTAs
🏷️ Generating hashtags...
✅ Hashtags: #SherlockHolmes #AudioDrama #MysteryStory #VictorianLondon #DetectiveFiction #ClassicLiterature #Audiobook #CrimeMystery #221BBakerStreet #DrWatson #ConanDoyle #Suspense #FullAudiobook #VictorianMystery #Case
📝 Rendering final description...
✅ Description rendered (1994 characters)
💾 Saving description to ../output/description.txt...
✅ Description saved
🏷️ Generating YouTube tags...
✅ Generated 30 initial tags
🧹 Normalizing and trimming tags...
✅ After normalization: 13 tags
🔄 Deduplicating tags...
✅ After deduplication: 12 tags
✂️ Fitting to 500 character limit...
✅ Final tags: 12 tags (218 chars)
💾 Saving tags to ../output/tags.txt...
✅ Tags saved
Saved YouTube description to: ../output/description.txt (took 28.51s)

===== END D:\.comfyui\gen.audio\scripts\12.media.py @ 2025-10-04 11:48:07 (exit=0, took=28.66s) =====
Stopping LM Studio backend via lms CLI...
Command: lms server stop
Unloading all models from LM Studio...
Command: lms unload --all
Unloading "qwen/qwen3-14b"...
Unloaded 1 model.
Stopped the server on port 1234.
LM Studio appears stopped (after 1 checks).

Log time stats: writes=0.000s, flushes=0.000s, total=0.001s (~0.00% of runtime)

All scripts completed successfully.
